# SubcapÃ­tulo 9.F: MCP de Google Cloud Platform - Gestiona GCP

**DuraciÃ³n**: 60 minutos
**Dificultad**: Avanzado
**Prerrequisito**: CapÃ­tulo 9 (MCP BÃ¡sico)

---

## ğŸ¯ Objetivos de Aprendizaje

Al final de este subcapÃ­tulo, podrÃ¡s:
- Entender quÃ© es el MCP de GCP y sus capacidades cloud
- Configurar autenticaciÃ³n con Service Accounts
- Gestionar recursos de Google Cloud (Compute, Storage, etc)
- Desplegar aplicaciones en Cloud Run y Cloud Functions
- Administrar bases de datos (Cloud SQL, Firestore, BigQuery)
- Optimizar costos y billing de GCP
- Implementar seguridad con IAM y Security Command Center
- Usar herramientas de IA/ML de Google Cloud

---

## ğŸ“– LecciÃ³n 9.F.1: Â¿QuÃ© es el MCP de GCP?

El **MCP de Google Cloud Platform** es un servidor que conecta Claude Code directamente con GCP, permitiÃ©ndote gestionar infraestructura cloud, deployments, bases de datos, IA/ML y mÃ¡s usando lenguaje natural.

### Concepto Fundamental

Piensa en el MCP de GCP como un **Cloud Architect automatizado**:

**Sin MCP de GCP:**
```
TÃº â†â†’ Claude Code
       â†“ (manualmente)
   Console/gcloud CLI â†â†’ Google Cloud
   (comandos complejos, clicks en UI)
```

**Con MCP de GCP:**
```
TÃº â†â†’ Claude Code â†â†’ MCP GCP â†â†’ Google Cloud
     ("despliega en Cloud Run" â†’ automatizaciÃ³n completa)
```

### Â¿QuÃ© Puede Hacer?

El MCP de GCP proporciona **herramientas poderosas** para:

âœ… **Compute y Containers**
- Google Compute Engine (VMs)
- Google Kubernetes Engine (GKE)
- Cloud Run (serverless containers)
- Cloud Functions (serverless functions)

âœ… **Storage y Databases**
- Cloud Storage (object storage)
- Cloud SQL (PostgreSQL, MySQL)
- Firestore (NoSQL)
- BigQuery (data warehouse)

âœ… **Networking**
- VPC networks
- Load balancers
- Cloud CDN
- Cloud DNS

âœ… **AI/ML Services**
- Vertex AI (ML platform)
- Vision API (image analysis)
- Natural Language API
- Translation API

âœ… **Security y IAM**
- Identity and Access Management
- Security Command Center
- Secret Manager
- Cloud Armor

âœ… **DevOps**
- Cloud Build (CI/CD)
- Artifact Registry
- Cloud Logging
- Cloud Monitoring

### Ventajas Clave

| Sin MCP GCP | Con MCP GCP |
|-------------|-------------|
| gcloud commands complejos | Lenguaje natural |
| Console web manual | AutomatizaciÃ³n desde Claude |
| Scripts complicados | GeneraciÃ³n automÃ¡tica |
| DocumentaciÃ³n fragmentada | Claude conoce best practices |
| ConfiguraciÃ³n propensa a errores | ValidaciÃ³n automÃ¡tica |
| **Curva de aprendizaje alta** | **IntuiciÃ³n natural** âš¡ |

---

## ğŸ“– LecciÃ³n 9.F.2: InstalaciÃ³n y ConfiguraciÃ³n

### Paso 1: Crear Service Account en GCP

**OpciÃ³n A: Usando gcloud CLI**
```bash
# Login en GCP
gcloud auth login

# Establecer proyecto
gcloud config set project mi-proyecto-gcp

# Crear service account
gcloud iam service-accounts create claude-code-sa \
  --display-name="Claude Code MCP" \
  --description="Service account for Claude Code automation"

# Dar permisos (ajustar segÃºn necesidad)
gcloud projects add-iam-policy-binding mi-proyecto-gcp \
  --member="serviceAccount:claude-code-sa@mi-proyecto-gcp.iam.gserviceaccount.com" \
  --role="roles/editor"

# Crear y descargar key
gcloud iam service-accounts keys create ~/claude-gcp-key.json \
  --iam-account=claude-code-sa@mi-proyecto-gcp.iam.gserviceaccount.com
```

**OpciÃ³n B: Desde GCP Console**
```
1. Console â†’ IAM & Admin â†’ Service Accounts
2. Create Service Account
3. Name: claude-code-sa
4. Grant roles: Editor (o roles especÃ­ficos)
5. Create key â†’ JSON
6. Descargar archivo JSON
```

### Paso 2: Instalar el Servidor MCP

```bash
# Instalar el MCP de GCP
npm install -g @modelcontextprotocol/server-gcp

# O usando Claude Code CLI
claude mcp add --transport stdio \
  --name gcp \
  --command "npx" \
  --args "-y @modelcontextprotocol/server-gcp"
```

### Paso 3: ConfiguraciÃ³n Manual

**Archivo: `.claude/mcp.json`** (proyecto especÃ­fico)
```json
{
  "servers": {
    "gcp": {
      "transport": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-gcp"
      ],
      "env": {
        "GOOGLE_APPLICATION_CREDENTIALS": "/path/to/claude-gcp-key.json",
        "GCP_PROJECT_ID": "mi-proyecto-gcp"
      }
    }
  }
}
```

O en **`~/.claude/mcp.json`** (global - todos los proyectos)

### Paso 4: Usar Variables de Entorno (Recomendado)

**Archivo: `.env`**
```bash
GOOGLE_APPLICATION_CREDENTIALS=/home/usuario/.gcp/claude-gcp-key.json
GCP_PROJECT_ID=mi-proyecto-gcp
GCP_REGION=us-central1
GCP_ZONE=us-central1-a
```

**Actualiza `mcp.json`:**
```json
{
  "servers": {
    "gcp": {
      "transport": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-gcp"],
      "env": {
        "GOOGLE_APPLICATION_CREDENTIALS": "${GOOGLE_APPLICATION_CREDENTIALS}",
        "GCP_PROJECT_ID": "${GCP_PROJECT_ID}",
        "GCP_REGION": "${GCP_REGION}",
        "GCP_ZONE": "${GCP_ZONE}"
      }
    }
  }
}
```

### Paso 5: MÃºltiples Proyectos

Si gestionas mÃºltiples proyectos de GCP:

```json
{
  "servers": {
    "gcp-production": {
      "transport": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-gcp"],
      "env": {
        "GOOGLE_APPLICATION_CREDENTIALS": "${GCP_PROD_CREDENTIALS}",
        "GCP_PROJECT_ID": "${GCP_PROD_PROJECT_ID}"
      }
    },
    "gcp-development": {
      "transport": "stdio",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-gcp"],
      "env": {
        "GOOGLE_APPLICATION_CREDENTIALS": "${GCP_DEV_CREDENTIALS}",
        "GCP_PROJECT_ID": "${GCP_DEV_PROJECT_ID}"
      }
    }
  }
}
```

### Verificar InstalaciÃ³n

```bash
# Listar servidores MCP
claude mcp list

# Salida esperada:
# gcp (stdio) - @modelcontextprotocol/server-gcp [connected âœ“]
```

### Probar ConexiÃ³n

```
TÃº: Â¿Puedes conectarte a Google Cloud?

Claude: [usa gcp_test_connection]
âœ“ ConexiÃ³n exitosa a Google Cloud Platform
Project: mi-proyecto-gcp
Project Number: 123456789012
Region: us-central1
Service Account: claude-code-sa@mi-proyecto-gcp.iam.gserviceaccount.com
Active Services: 45
```

---

## ğŸ“– LecciÃ³n 9.F.3: Cloud Run - Serverless Containers

### Desplegar AplicaciÃ³n en Cloud Run

**Herramienta: gcp_deploy_cloud_run**

```
TÃº: Despliega mi aplicaciÃ³n Node.js a Cloud Run

Claude: [analiza proyecto y despliega]

Detectando configuraciÃ³n...
âœ“ Proyecto: API Express.js
âœ“ Puerto: 3000
âœ“ Dependencies: 23 packages

[Creando Dockerfile optimizado]

```dockerfile
# Multi-stage build para optimizaciÃ³n
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM node:18-alpine

WORKDIR /app
COPY --from=builder /app/node_modules ./node_modules
COPY . .

ENV NODE_ENV=production
ENV PORT=8080
EXPOSE 8080

CMD ["node", "server.js"]
```

[Building container]
â–¸ Building with Cloud Build...
  Step 1/8: FROM node:18-alpine
  Step 2/8: WORKDIR /app
  Step 3/8: COPY package*.json
  Step 4/8: RUN npm ci
  ...
  âœ“ Build successful (2m 15s)

â–¸ Pushing to Artifact Registry...
  gcr.io/mi-proyecto-gcp/mi-api:latest
  âœ“ Pushed (45s)

[Deploying to Cloud Run]
â–¸ Creating Cloud Run service...
  Region: us-central1
  Service: mi-api
  Platform: managed
  Concurrency: 80
  Max instances: 100
  Min instances: 0 (scale to zero)
  CPU: 1 vCPU
  Memory: 512 MB
  Request timeout: 300s

â–¸ Configuring traffic...
  100% â†’ Revision mi-api-00001

âœ… Deployment successful!

Service URL: https://mi-api-abc123-uc.a.run.app

CaracterÃ­sticas:
âœ“ HTTPS automÃ¡tico
âœ“ Auto-scaling (0-100 instances)
âœ“ Pay per request (scale to zero)
âœ“ Global anycast
âœ“ Managed infrastructure

Cold start: ~500ms
Pricing: $0.00002400 per request

Â¿Quieres configurar un dominio personalizado?
```

### Configurar Dominio Personalizado

```
TÃº: SÃ­, configura el dominio api.miapp.com

Claude: [configura domain mapping]

Configurando dominio personalizado...

[Domain Mapping]
âœ“ Verificando propiedad del dominio
âœ“ Domain: api.miapp.com
âœ“ Service: mi-api
âœ“ Region: us-central1

[DNS Configuration]
Agregar estos registros DNS:

Type: CNAME
Name: api
Value: ghs.googlehosted.com

[SSL Certificate]
âœ“ Certificado SSL gestionado por Google
âœ“ Provisioning automÃ¡tico
âœ“ Auto-renewal habilitado

Status:
ğŸŸ¡ Pendiente de verificaciÃ³n DNS

Una vez que el DNS se propague (~15 minutos):
âœ“ SSL certificate emitido
âœ“ HTTPS habilitado
âœ“ api.miapp.com â†’ Cloud Run service

Te notificarÃ© cuando estÃ© listo.
```

### Configurar CI/CD con Cloud Build

```
TÃº: Configura CI/CD para que cada push a main despliegue automÃ¡ticamente

Claude: [crea Cloud Build pipeline]

Configurando CI/CD automÃ¡tico...

[Creando cloudbuild.yaml]

```yaml
# cloudbuild.yaml
steps:
  # Install dependencies
  - name: 'node:18'
    entrypoint: npm
    args: ['ci']

  # Run tests
  - name: 'node:18'
    entrypoint: npm
    args: ['test']

  # Build container
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/mi-api:$COMMIT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/mi-api:latest'
      - '.'

  # Push to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - 'gcr.io/$PROJECT_ID/mi-api'

  # Deploy to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'mi-api'
      - '--image'
      - 'gcr.io/$PROJECT_ID/mi-api:$COMMIT_SHA'
      - '--region'
      - 'us-central1'
      - '--platform'
      - 'managed'

# Store images in Artifact Registry
images:
  - 'gcr.io/$PROJECT_ID/mi-api:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/mi-api:latest'

options:
  logging: CLOUD_LOGGING_ONLY
```

[Creando Cloud Build Trigger]
âœ“ Trigger name: deploy-on-push-main
âœ“ Source: GitHub (mi-usuario/mi-repo)
âœ“ Branch: ^main$
âœ“ Config: cloudbuild.yaml

[Permisos]
âœ“ Cloud Build service account configurado
âœ“ Permisos para Cloud Run deployment

âœ… CI/CD configurado

Workflow:
1. Push to main branch
2. Cloud Build trigger activado
3. Tests ejecutados
4. Container built y pushed
5. Deployed to Cloud Run
6. NotificaciÃ³n enviada

PrÃ³ximo push a main desplegarÃ¡ automÃ¡ticamente ğŸš€
```

---

## ğŸ“– LecciÃ³n 9.F.4: Cloud Functions - Serverless

### Crear Cloud Function

**Herramienta: gcp_create_function**

```
TÃº: Crea una Cloud Function para procesar webhooks de Stripe

Claude: GenerarÃ© una Cloud Function optimizada...

[Creando funciÃ³n]

```javascript
// index.js
const stripe = require('stripe')(process.env.STRIPE_SECRET_KEY);
const { Firestore } = require('@google-cloud/firestore');

const firestore = new Firestore();

/**
 * HTTP Cloud Function para webhooks de Stripe
 * @param {Object} req Express request object
 * @param {Object} res Express response object
 */
exports.stripeWebhook = async (req, res) => {
  const sig = req.headers['stripe-signature'];
  let event;

  try {
    // Verificar webhook signature
    event = stripe.webhooks.constructEvent(
      req.rawBody,
      sig,
      process.env.STRIPE_WEBHOOK_SECRET
    );
  } catch (err) {
    console.error('Webhook signature verification failed:', err.message);
    return res.status(400).send(`Webhook Error: ${err.message}`);
  }

  // Procesar evento
  console.log('Processing event:', event.type);

  try {
    switch (event.type) {
      case 'payment_intent.succeeded':
        await handlePaymentSuccess(event.data.object);
        break;

      case 'payment_intent.payment_failed':
        await handlePaymentFailure(event.data.object);
        break;

      case 'customer.subscription.created':
        await handleSubscriptionCreated(event.data.object);
        break;

      case 'customer.subscription.deleted':
        await handleSubscriptionCancelled(event.data.object);
        break;

      default:
        console.log(`Unhandled event type: ${event.type}`);
    }

    res.json({ received: true });
  } catch (error) {
    console.error('Error processing webhook:', error);
    res.status(500).json({ error: 'Webhook processing failed' });
  }
};

async function handlePaymentSuccess(paymentIntent) {
  const { id, amount, customer, metadata } = paymentIntent;

  await firestore.collection('payments').doc(id).set({
    paymentIntentId: id,
    amount: amount / 100,
    currency: paymentIntent.currency,
    customerId: customer,
    status: 'succeeded',
    metadata,
    processedAt: new Date()
  });

  console.log(`Payment ${id} processed successfully`);
}

async function handlePaymentFailure(paymentIntent) {
  const { id, last_payment_error } = paymentIntent;

  await firestore.collection('payment_failures').doc(id).set({
    paymentIntentId: id,
    error: last_payment_error?.message || 'Unknown error',
    failedAt: new Date()
  });

  console.error(`Payment ${id} failed:`, last_payment_error?.message);
}

async function handleSubscriptionCreated(subscription) {
  // Implementation...
}

async function handleSubscriptionCancelled(subscription) {
  // Implementation...
}
```

```json
// package.json
{
  "name": "stripe-webhook-handler",
  "version": "1.0.0",
  "dependencies": {
    "stripe": "^14.0.0",
    "@google-cloud/firestore": "^7.0.0"
  }
}
```

[Deploying]
â–¸ Function name: stripe-webhook-handler
â–¸ Runtime: Node.js 18
â–¸ Trigger: HTTP
â–¸ Region: us-central1
â–¸ Memory: 256 MB
â–¸ Timeout: 60s
â–¸ Max instances: 100

â–¸ Environment variables:
  STRIPE_SECRET_KEY: [Secret Manager ref]
  STRIPE_WEBHOOK_SECRET: [Secret Manager ref]

â–¸ Security:
  âœ“ Requires authentication: No (Stripe envia requests)
  âœ“ CORS: Disabled
  âœ“ Ingress: All

âœ“ Function deployed

URL: https://us-central1-mi-proyecto-gcp.cloudfunctions.net/stripe-webhook-handler

Configurar en Stripe Dashboard:
Webhooks â†’ Add endpoint â†’ [URL arriba]

Events to send:
â€¢ payment_intent.succeeded
â€¢ payment_intent.payment_failed
â€¢ customer.subscription.created
â€¢ customer.subscription.deleted

FunciÃ³n lista para recibir webhooks ğŸ‰
```

---

## ğŸ“– LecciÃ³n 9.F.5: Bases de Datos

### Cloud SQL (PostgreSQL)

**Herramienta: gcp_create_sql_instance**

```
TÃº: Crea una instancia de Cloud SQL PostgreSQL para producciÃ³n

Claude: [crea database instance]

Creando Cloud SQL instance...

[Configuration]
Instance ID: mi-app-postgres-prod
Database: PostgreSQL 15
Tier: db-n1-standard-2
  vCPUs: 2
  Memory: 7.5 GB
  Storage: 100 GB SSD (auto-increase enabled)

Region: us-central1
Zone: us-central1-a
High Availability: Enabled (failover replica)
Backup: Automated daily backups (7 day retention)

[Security]
âœ“ Private IP enabled
âœ“ SSL required
âœ“ Authorized networks configured
âœ“ IAM database authentication enabled

[Creating]
â–¸ Provisioning instance... (5-10 minutes)
  âœ“ Primary instance created
  âœ“ Failover replica created
  âœ“ Backups configured

âœ… Instance ready!

Connection info:
Private IP: 10.128.0.3
Public IP: 35.192.123.45 (use private IP)

Connection string:
postgresql://postgres:PASSWORD@10.128.0.3:5432/postgres

[Creating database]
âœ“ Database: mi_app_prod created

[Creating user]
âœ“ User: app_user created
âœ“ Password: [stored in Secret Manager]
âœ“ Privileges: Granted on mi_app_prod

Connection from Cloud Run/Functions:
Use Cloud SQL Proxy (automÃ¡tico) o
Private IP desde VPC

Estimated cost: ~$150/month

Â¿Quieres que configure Cloud SQL Proxy para tu app?
```

### Firestore (NoSQL)

```
TÃº: Configura Firestore para almacenar datos de usuarios

Claude: [configura Firestore]

Configurando Firestore...

[Setup]
âœ“ Mode: Native mode (recomendado)
âœ“ Location: nam5 (United States)
âœ“ No se puede cambiar despuÃ©s

[Collections structure]
DiseÃ±ando schema optimizado para tus datos...

```
firestore/
â”œâ”€â”€ users/
â”‚   â””â”€â”€ {userId}
â”‚       â”œâ”€â”€ email: string
â”‚       â”œâ”€â”€ name: string
â”‚       â”œâ”€â”€ createdAt: timestamp
â”‚       â”œâ”€â”€ profile/
â”‚       â”‚   â”œâ”€â”€ avatar: string
â”‚       â”‚   â”œâ”€â”€ bio: string
â”‚       â”‚   â””â”€â”€ settings: map
â”‚       â””â”€â”€ subscriptions/ (subcollection)
â”‚           â””â”€â”€ {subscriptionId}
â”‚               â”œâ”€â”€ plan: string
â”‚               â”œâ”€â”€ status: string
â”‚               â””â”€â”€ expiresAt: timestamp
â”‚
â”œâ”€â”€ products/
â”‚   â””â”€â”€ {productId}
â”‚       â”œâ”€â”€ name: string
â”‚       â”œâ”€â”€ price: number
â”‚       â”œâ”€â”€ category: string
â”‚       â”œâ”€â”€ stock: number
â”‚       â””â”€â”€ createdAt: timestamp
â”‚
â””â”€â”€ orders/
    â””â”€â”€ {orderId}
        â”œâ”€â”€ userId: string (indexed)
        â”œâ”€â”€ items: array
        â”œâ”€â”€ total: number
        â”œâ”€â”€ status: string (indexed)
        â””â”€â”€ createdAt: timestamp (indexed)
```

[Indexes]
Creando Ã­ndices compuestos...

âœ“ orders: userId + createdAt (desc)
âœ“ orders: status + createdAt (desc)
âœ“ products: category + price (asc)

[Security Rules]

```javascript
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    // Users can read/write their own data
    match /users/{userId} {
      allow read: if request.auth != null;
      allow write: if request.auth.uid == userId;

      // Profile subcollection
      match /profile/{document=**} {
        allow read: if request.auth != null;
        allow write: if request.auth.uid == userId;
      }

      // Subscriptions subcollection
      match /subscriptions/{subId} {
        allow read: if request.auth.uid == userId;
        allow write: if false; // Only server can write
      }
    }

    // Products - public read, admin write
    match /products/{productId} {
      allow read: if true;
      allow write: if request.auth.token.admin == true;
    }

    // Orders - user can read their own, admin all
    match /orders/{orderId} {
      allow read: if request.auth.uid == resource.data.userId
                  || request.auth.token.admin == true;
      allow create: if request.auth.uid == request.resource.data.userId;
      allow update: if request.auth.token.admin == true;
    }
  }
}
```

âœ“ Security rules deployed

[Client SDK example]

```javascript
import { initializeApp } from 'firebase/app';
import { getFirestore, collection, addDoc } from 'firebase/firestore';

const app = initializeApp({
  projectId: 'mi-proyecto-gcp',
  // ... other config
});

const db = getFirestore(app);

// Create user
await addDoc(collection(db, 'users'), {
  email: 'user@example.com',
  name: 'John Doe',
  createdAt: new Date()
});
```

Firestore listo para usar ğŸ”¥
```

### BigQuery (Data Warehouse)

```
TÃº: Configura BigQuery para analytics de la app

Claude: [configura BigQuery dataset y tables]

Configurando BigQuery...

[Dataset]
âœ“ Dataset: app_analytics
âœ“ Location: US (multi-region)
âœ“ Default table expiration: Never
âœ“ Encryption: Google-managed

[Tables]
Creando tablas para analytics...

1. events (streaming)
```sql
CREATE TABLE app_analytics.events (
  event_id STRING NOT NULL,
  event_name STRING NOT NULL,
  user_id STRING,
  timestamp TIMESTAMP NOT NULL,
  properties JSON,
  user_properties JSON,
  device_info STRUCT<
    platform STRING,
    os_version STRING,
    app_version STRING,
    screen_resolution STRING
  >,
  geo STRUCT<
    country STRING,
    region STRING,
    city STRING
  >
)
PARTITION BY DATE(timestamp)
CLUSTER BY event_name, user_id;
```

2. user_sessions
```sql
CREATE TABLE app_analytics.user_sessions (
  session_id STRING NOT NULL,
  user_id STRING,
  start_time TIMESTAMP,
  end_time TIMESTAMP,
  duration_seconds INT64,
  page_views INT64,
  events_count INT64,
  device_category STRING
)
PARTITION BY DATE(start_time)
CLUSTER BY user_id;
```

[Views]
Creando vistas Ãºtiles...

```sql
-- Daily active users
CREATE VIEW app_analytics.daily_active_users AS
SELECT
  DATE(timestamp) as date,
  COUNT(DISTINCT user_id) as dau
FROM app_analytics.events
GROUP BY date
ORDER BY date DESC;

-- Popular features
CREATE VIEW app_analytics.popular_features AS
SELECT
  event_name,
  COUNT(*) as event_count,
  COUNT(DISTINCT user_id) as unique_users
FROM app_analytics.events
WHERE DATE(timestamp) >= DATE_SUB(CURRENT_DATE(), INTERVAL 30 DAY)
GROUP BY event_name
ORDER BY event_count DESC;
```

[Streaming Insert Example]

```javascript
const { BigQuery } = require('@google-cloud/bigquery');
const bigquery = new BigQuery();

async function trackEvent(event) {
  const rows = [{
    event_id: generateId(),
    event_name: event.name,
    user_id: event.userId,
    timestamp: new Date().toISOString(),
    properties: event.properties,
    device_info: event.device
  }];

  await bigquery
    .dataset('app_analytics')
    .table('events')
    .insert(rows);
}
```

[Scheduled Queries]
âœ“ Daily aggregations scheduled
âœ“ Weekly reports scheduled

BigQuery configurado para analytics a escala ğŸ“Š
```

---

## ğŸ“– LecciÃ³n 9.F.6: OptimizaciÃ³n de Costos

### Analizar Billing

**Herramienta: gcp_analyze_billing**

```
TÃº: Â¿CuÃ¡nto estoy gastando en GCP este mes?

Claude: [analiza billing data]

ğŸ’° GCP BILLING ANALYSIS - Octubre 2025

*Resumen Mensual:*
Gasto actual: $2,345.67
Forecast fin de mes: $3,100.00
Budget: $3,500.00
UtilizaciÃ³n: 88.6%

*Gasto por Servicio:*
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Servicio            â”‚ Costo    â”‚ %      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cloud Run           â”‚ $890.00  â”‚ 37.9%  â”‚
â”‚ Cloud SQL           â”‚ $567.00  â”‚ 24.2%  â”‚
â”‚ Cloud Storage       â”‚ $345.00  â”‚ 14.7%  â”‚
â”‚ BigQuery            â”‚ $234.00  â”‚ 10.0%  â”‚
â”‚ Cloud Functions     â”‚ $123.00  â”‚ 5.2%   â”‚
â”‚ Cloud Build         â”‚ $89.00   â”‚ 3.8%   â”‚
â”‚ Networking          â”‚ $67.00   â”‚ 2.9%   â”‚
â”‚ Otros               â”‚ $30.67   â”‚ 1.3%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

*Tendencia:*
Semana 1: $523
Semana 2: $578
Semana 3: $612 â† Incremento
Semana 4: $633 (proyecciÃ³n)

*Gasto por RegiÃ³n:*
us-central1: $1,890 (80.6%)
us-east1: $345 (14.7%)
europe-west1: $110.67 (4.7%)

*Top Recursos Costosos:*
1. Cloud SQL: mi-app-postgres-prod ($450/mes)
2. Cloud Run: mi-api (100M requests) ($340/mes)
3. Cloud Storage: backups bucket (2.3TB) ($230/mes)
4. BigQuery: analytics queries (5TB processed) ($234/mes)
5. Cloud Run: worker-service ($210/mes)

âš ï¸ Recomendaciones de ahorro disponibles
```

### Optimizar Costos

```
Claude: [analiza oportunidades]

ğŸ’¡ OPORTUNIDADES DE OPTIMIZACIÃ“N

*Alta Prioridad:*

1. ğŸ”´ Cloud SQL Over-Provisioned
   Recurso: mi-app-postgres-prod
   Tier actual: db-n1-standard-2 (2 vCPU, 7.5GB)
   UtilizaciÃ³n: CPU 18%, RAM 32%

   RecomendaciÃ³n: Downgrade a db-n1-standard-1
   Ahorro: $225/mes ($2,700/aÃ±o)

2. ğŸ”´ Cloud Storage Lifecycle Policy
   Bucket: backups (2.3TB)
   Tier: Standard (acceso < 1 vez/mes)

   RecomendaciÃ³n:
   - Nearline para backups 7-30 dÃ­as
   - Coldline para backups > 30 dÃ­as
   - Archive para backups > 90 dÃ­as

   Ahorro: $138/mes ($1,656/aÃ±o)

3. ğŸ”´ BigQuery Partitioning
   Table: events (sin particiones)
   Queries escanean toda la tabla

   RecomendaciÃ³n: Partition por fecha
   Ahorro: ~40% en query costs ($94/mes)

*Media Prioridad:*

4. ğŸŸ¡ Committed Use Discounts
   Cloud Run requests: Consistentemente alto

   RecomendaciÃ³n: 1-year commitment
   Ahorro: 20% (~$68/mes)

5. ğŸŸ¡ Cloud Build Cache
   Builds reconstruyen todo cada vez

   RecomendaciÃ³n: Habilitar cache layers
   Ahorro: ~30% build time ($27/mes)

*Total Ahorro Potencial:*
Inmediato: $457/mes ($5,484/aÃ±o)
Con commitment: $525/mes ($6,300/aÃ±o)

Â¿Implemento las optimizaciones de alta prioridad?
```

### Implementar Optimizaciones

```
TÃº: SÃ­, implementa todas las de alta prioridad

Claude: [aplica optimizaciones]

Aplicando optimizaciones...

1. [Cloud SQL Resize]
   mi-app-postgres-prod: db-n1-standard-2 â†’ db-n1-standard-1

   Safety checks:
   âœ“ Current load permite downgrade
   âœ“ Connection pool ajustado
   âœ“ No downtime (hot resize)

   [Ejecutando]
   âœ“ Instance resized
   âœ“ Application unaffected
   âœ“ Monitoring confirmado

   Ahorro: $225/mes âœ…

2. [Storage Lifecycle Policy]
   Bucket: backups

   [Creating policy]
   ```json
   {
     "lifecycle": {
       "rule": [
         {
           "action": {"type": "SetStorageClass", "storageClass": "NEARLINE"},
           "condition": {"age": 7, "matchesStorageClass": ["STANDARD"]}
         },
         {
           "action": {"type": "SetStorageClass", "storageClass": "COLDLINE"},
           "condition": {"age": 30, "matchesStorageClass": ["NEARLINE"]}
         },
         {
           "action": {"type": "SetStorageClass", "storageClass": "ARCHIVE"},
           "condition": {"age": 90, "matchesStorageClass": ["COLDLINE"]}
         },
         {
           "action": {"type": "Delete"},
           "condition": {"age": 365}
         }
       ]
     }
   }
   ```

   âœ“ Policy applied
   âœ“ Existing objects will transition

   Ahorro: $138/mes âœ…

3. [BigQuery Partitioning]
   Table: app_analytics.events

   [Creating partitioned table]
   ```sql
   CREATE TABLE app_analytics.events_partitioned
   PARTITION BY DATE(timestamp)
   CLUSTER BY event_name, user_id
   AS SELECT * FROM app_analytics.events;
   ```

   [Migrating]
   âœ“ Data copied to partitioned table
   âœ“ Views updated
   âœ“ Old table renamed to events_backup

   [Testing queries]
   Before: Scanned 450GB
   After: Scanned 15GB (last 30 days)
   Improvement: 97% less data scanned

   Ahorro: $94/mes âœ…

âœ… OPTIMIZACIONES COMPLETADAS

Total ahorro: $457/mes ($5,484/aÃ±o)
Nuevo costo estimado: $2,643/aÃ±o
Budget utilization: 75.5% (bajÃ³ de 88.6%)

Monitoreando performance por 48 horas...
```

---

## ğŸ“– LecciÃ³n 9.F.7: Seguridad - IAM y SecOps

### Security Command Center

**Herramienta: gcp_security_scan**

```
TÃº: Ejecuta un security scan completo del proyecto

Claude: [ejecuta security assessment]

ğŸ” SECURITY COMMAND CENTER - Scan Results

*Security Health Score: 82/100* (Bueno)

*Hallazgos CrÃ­ticos:* ğŸ”´ (3)

1. Public Cloud Storage Bucket
   Bucket: mi-app-uploads
   Problema: Public access habilitado
   Riesgo: ExposiciÃ³n de datos sensibles
   Impacto: CRITICAL

   Afectado: ~2,300 archivos
   Incluyendo: Documentos de usuarios

   RemediaciÃ³n:
   - Quitar allUsers permiso
   - Implementar Signed URLs
   - Habilitar Uniform bucket-level access

2. Service Account con demasiados permisos
   SA: cloud-run-worker@...iam.gserviceaccount.com
   Rol actual: Editor (muy permisivo)

   Problema: Principio de least privilege violado
   Riesgo: Lateral movement si comprometido

   RemediaciÃ³n:
   - Usar roles especÃ­ficos:
     * Storage Object Viewer
     * Firestore User
     * Cloud SQL Client

3. API Keys sin restricciones
   Key: AIzaSy...
   Used by: Frontend application
   Restricciones: Ninguna

   Riesgo: Uso no autorizado si key leak

   RemediaciÃ³n:
   - RestricciÃ³n por HTTP referrers
   - RestricciÃ³n por API especÃ­fica
   - Rotar key

*Hallazgos Importantes:* ğŸŸ¡ (5)

4. Logs retention demasiado corto
   Cloud Logging: 30 dÃ­as
   RecomendaciÃ³n: 90+ dÃ­as para compliance

5. No hay alertas de security events
   Sin alertas configuradas para:
   - IAM policy changes
   - Admin activity
   - Data access

6. Firewall rules permisivas
   Rule: allow-ssh-from-anywhere
   Source: 0.0.0.0/0
   Recommendation: Restrict to VPN/bastion

7. SSL certificates cerca de expiraciÃ³n
   Certificate: *.miapp.com
   Expires: En 15 dÃ­as

8. MFA no habilitado para todos
   Users sin MFA: 3 de 8

*Compliance Checks:*
CIS GCP Foundation: 78% compliant
PCI-DSS: 85% compliant
SOC 2: 82% compliant

Â¿Remediar hallazgos crÃ­ticos ahora?
```

### Implementar Security Fixes

```
TÃº: SÃ­, arregla todos los crÃ­ticos

Claude: [aplica security remediations]

Aplicando security fixes...

1. [Cloud Storage - Remove Public Access]
   Bucket: mi-app-uploads

   [Analyzing access]
   Current: allUsers can view
   Usage: 2,345 public requests/day

   [Implementing secure access]
   âœ“ Removed allUsers permission
   âœ“ Enabled Uniform bucket-level access
   âœ“ Generated Signed URLs for existing links

   [Code for app]
   ```javascript
   const { Storage } = require('@google-cloud/storage');
   const storage = new Storage();

   async function getSignedUrl(filename) {
     const options = {
       version: 'v4',
       action: 'read',
       expires: Date.now() + 15 * 60 * 1000, // 15 minutes
     };

     const [url] = await storage
       .bucket('mi-app-uploads')
       .file(filename)
       .getSignedUrl(options);

     return url;
   }
   ```

   âœ“ App code updated
   âœ“ Deployment tested
   âœ“ Public access removed

2. [Service Account - Least Privilege]
   SA: cloud-run-worker@

   Current roles:
   âŒ Editor (broad permissions)

   Applying specific roles:
   âœ“ roles/storage.objectViewer
   âœ“ roles/datastore.user
   âœ“ roles/cloudsql.client

   [Testing]
   âœ“ Worker service functional
   âœ“ No permission errors
   âœ“ Minimum permissions confirmed

3. [API Key Restrictions]
   Key: AIzaSy...

   Applying restrictions:
   âœ“ HTTP referrers:
     - https://miapp.com/*
     - https://*.miapp.com/*

   âœ“ API restrictions:
     - Maps JavaScript API
     - Places API

   âœ“ New restricted key created
   âœ“ Old key scheduled for deletion (7 days)
   âœ“ Frontend updated with new key

[Security Posture]
Before: 82/100
After: 95/100 (+13 points) ğŸ‰

Critical issues: 3 â†’ 0 âœ…
Important issues: 5 â†’ 2

Remaining items:
â€¢ Configure security alerts (recommended)
â€¢ Extend log retention to 90 days
â€¢ Enable MFA for remaining users

Â¿ContinÃºo con los items importantes?
```

---

## ğŸ“– LecciÃ³n 9.F.8: AI/ML con Vertex AI

### Usar Vision API

```
TÃº: Analiza las imÃ¡genes subidas por usuarios para detectar contenido inapropiado

Claude: [integra Vision API]

Configurando Vision API para content moderation...

[Habilitando API]
âœ“ Cloud Vision API enabled

[Creating Cloud Function]

```javascript
const vision = require('@google-cloud/vision');
const { Storage } = require('@google-cloud/storage');
const { Firestore } = require('@google-cloud/firestore');

const client = new vision.ImageAnnotatorClient();
const storage = new Storage();
const firestore = new Firestore();

exports.moderateImage = async (file, context) => {
  const filePath = `gs://${file.bucket}/${file.name}`;

  console.log(`Analyzing image: ${filePath}`);

  try {
    // Safe Search Detection
    const [result] = await client.safeSearchDetection(filePath);
    const safeSearch = result.safeSearchAnnotation;

    // Label Detection (what's in the image)
    const [labels] = await client.labelDetection(filePath);
    const imageLabels = labels.labelAnnotations.map(l => l.description);

    // Explicit Content Detection
    const isExplicit =
      safeSearch.adult === 'VERY_LIKELY' ||
      safeSearch.violence === 'VERY_LIKELY';

    const isSuspicious =
      safeSearch.adult === 'LIKELY' ||
      safeSearch.violence === 'LIKELY' ||
      safeSearch.racy === 'VERY_LIKELY';

    // Store analysis results
    await firestore.collection('image_moderation').doc(file.name).set({
      filePath,
      uploadedAt: new Date(context.timestamp),
      safeSearch: {
        adult: safeSearch.adult,
        violence: safeSearch.violence,
        racy: safeSearch.racy,
        medical: safeSearch.medical,
        spoof: safeSearch.spoof
      },
      labels: imageLabels,
      status: isExplicit ? 'rejected' : isSuspicious ? 'review' : 'approved'
    });

    // Take action based on results
    if (isExplicit) {
      // Delete file
      await storage.bucket(file.bucket).file(file.name).delete();
      console.log(`Deleted explicit content: ${file.name}`);

      // Notify admin
      await notifyAdmin({
        type: 'explicit_content_detected',
        file: file.name,
        analysis: safeSearch
      });
    } else if (isSuspicious) {
      // Flag for manual review
      await flagForReview(file.name);
      console.log(`Flagged for review: ${file.name}`);
    } else {
      console.log(`Image approved: ${file.name}`);
    }

  } catch (error) {
    console.error('Error analyzing image:', error);
  }
};

async function notifyAdmin(alert) {
  // Send notification (email, Slack, etc)
}

async function flagForReview(fileName) {
  // Add to review queue
}
```

[Deploying]
âœ“ Function: moderate-images
âœ“ Trigger: Cloud Storage (on file upload)
âœ“ Bucket: mi-app-uploads
âœ“ Runtime: Node.js 18

[Testing]
Uploaded test images:
âœ“ Safe image â†’ Approved âœ…
âœ“ Violent image â†’ Rejected ğŸš«
âœ“ Borderline image â†’ Flagged for review âš ï¸

Content moderation activo ğŸ›¡ï¸

Workflow:
1. Usuario sube imagen
2. Vision API analiza automÃ¡ticamente
3. Contenido inapropiado eliminado
4. Admin notificado de problemas
5. Safe content aprobado

ProtecciÃ³n automÃ¡tica contra contenido no deseado.
```

### Natural Language API

```
TÃº: Analiza el sentiment de reviews de usuarios

Claude: [integra Natural Language API]

```javascript
const language = require('@google-cloud/language');
const client = new language.LanguageServiceClient();

exports.analyzeReview = async (req, res) => {
  const { reviewText, productId } = req.body;

  // Sentiment Analysis
  const [sentiment] = await client.analyzeSentiment({
    document: {
      content: reviewText,
      type: 'PLAIN_TEXT',
    },
  });

  const score = sentiment.documentSentiment.score;
  const magnitude = sentiment.documentSentiment.magnitude;

  // Entity Recognition
  const [entities] = await client.analyzeEntities({
    document: {
      content: reviewText,
      type: 'PLAIN_TEXT',
    },
  });

  const mentions = entities.entities.map(entity => ({
    name: entity.name,
    type: entity.type,
    salience: entity.salience,
  }));

  // Classify sentiment
  let sentimentLabel;
  if (score > 0.25) sentimentLabel = 'positive';
  else if (score < -0.25) sentimentLabel = 'negative';
  else sentimentLabel = 'neutral';

  // Save analysis
  const analysis = {
    productId,
    reviewText,
    sentiment: {
      score,
      magnitude,
      label: sentimentLabel,
    },
    entities: mentions,
    analyzedAt: new Date(),
  };

  await firestore.collection('review_analysis').add(analysis);

  res.json(analysis);
};
```

[Analysis Example]

Review: "This product is amazing! Fast shipping and great quality."

Result:
```json
{
  "sentiment": {
    "score": 0.8,
    "magnitude": 0.9,
    "label": "positive"
  },
  "entities": [
    {"name": "product", "type": "CONSUMER_GOOD", "salience": 0.7},
    {"name": "shipping", "type": "OTHER", "salience": 0.3}
  ]
}
```

Review: "Terrible experience. Product broke after 2 days."

Result:
```json
{
  "sentiment": {
    "score": -0.9,
    "magnitude": 1.0,
    "label": "negative"
  },
  "entities": [
    {"name": "experience", "type": "OTHER", "salience": 0.5},
    {"name": "Product", "type": "CONSUMER_GOOD", "salience": 0.5}
  ]
}
```

Use cases:
â€¢ Product quality monitoring
â€¢ Customer satisfaction tracking
â€¢ Auto-prioritize negative reviews
â€¢ Identify trending issues

Sentiment analysis activo ğŸ“Š
```

---

## ğŸ› ï¸ Ejercicios PrÃ¡cticos

### Ejercicio 9.F.1: Setup BÃ¡sico
1. Crea un Service Account en GCP
2. Configura el MCP de GCP
3. Verifica la conexiÃ³n
4. Lista tus proyectos y recursos
5. Documenta la configuraciÃ³n

### Ejercicio 9.F.2: Deploy Serverless
1. Crea una aplicaciÃ³n simple (API o web)
2. DespliÃ©gala a Cloud Run
3. Configura dominio personalizado
4. Configura CI/CD con Cloud Build
5. Verifica deployments automÃ¡ticos

### Ejercicio 9.F.3: Databases
1. Crea una instancia de Cloud SQL o Firestore
2. DiseÃ±a schema para tu aplicaciÃ³n
3. Implementa conexiÃ³n desde Cloud Run
4. Ejecuta queries de prueba
5. Documenta la arquitectura

### Ejercicio 9.F.4: Seguridad
1. Ejecuta security scan completo
2. Identifica vulnerabilidades
3. RemedÃ­a hallazgos crÃ­ticos
4. Configura alertas de seguridad
5. Documenta mejoras

### Ejercicio 9.F.5: AI/ML
1. Implementa Vision API para tu app
2. O Natural Language API
3. Crea Cloud Function para procesamiento
4. Prueba con datos reales
5. Analiza resultados

---

## ğŸ“ Examen 9.F: MaestrÃ­a del MCP de GCP

### Parte 1: Preguntas TeÃ³ricas (3 puntos)

**Pregunta 1:** Â¿CuÃ¡les son las 3 principales ventajas de gestionar GCP desde Claude Code?

**Pregunta 2:** Explica cuÃ¡ndo usar cada servicio:
- a) Cloud Run vs Cloud Functions vs GKE
- b) Cloud SQL vs Firestore vs BigQuery
- c) Standard Storage vs Nearline vs Coldline
- d) Committed Use vs On-Demand pricing

**Pregunta 3:** Â¿QuÃ© es el principio de "least privilege" y cÃ³mo aplicarlo en IAM de GCP?

### Parte 2: ConfiguraciÃ³n (2 puntos)

1. Muestra cÃ³mo crear un Service Account con permisos mÃ­nimos
2. Configura el MCP de GCP para mÃºltiples proyectos
3. Explica cÃ³mo proteger las credenciales

### Parte 3: PrÃ¡ctica - AplicaciÃ³n Completa (5 puntos)

Escenario: Despliega una aplicaciÃ³n full-stack en GCP.

**Requisitos:**
- Backend API en Cloud Run
- Frontend web
- Database (Cloud SQL o Firestore)
- Storage para archivos
- CI/CD automÃ¡tico

**Tareas:**
1. DiseÃ±a la arquitectura
2. Despliega todos los componentes
3. Configura seguridad (IAM, networks)
4. Implementa monitoring
5. Optimiza costos

Documenta todo desde Claude Code.

### Parte 4: Proyecto Real (Bonus +3 puntos)

Elige uno:

**OpciÃ³n A: Content Moderation System**
1. Implementa sistema completo de moderaciÃ³n con:
   - Vision API para imÃ¡genes
   - Natural Language para texto
   - Cloud Functions para procesamiento
   - Firestore para resultados
2. Incluye auto-deletion de contenido inapropiado
3. Dashboard de analytics

**OpciÃ³n B: Cost Optimization Project**
1. Analiza proyecto GCP real
2. Identifica todas las optimizaciones
3. Implementa mejoras (mÃ­nimo 10)
4. Calcula ROI
5. Documenta proceso completo

---

## âœ… CÃ³mo Enviar Tu Examen

### Para la Parte 1:
```
Parte 1:
P1: [respuesta]
P2: [respuestas detalladas]
P3: [explicaciÃ³n de least privilege]
```

### Para la Parte 2:
Archivos de configuraciÃ³n y procedimientos.

### Para la Parte 3:
- Diagrama de arquitectura
- Comandos/configuraciÃ³n usados
- URLs de servicios
- Evidencia de funcionamiento

### Para la Parte 4:
- CÃ³digo completo
- Screenshots
- MÃ©tricas de performance/costos
- DocumentaciÃ³n
- Lecciones aprendidas

---

## ğŸ¯ Checklist de Dominio

**ConfiguraciÃ³n**
- [ ] Service Account creation
- [ ] MCP de GCP setup
- [ ] MÃºltiples proyectos
- [ ] Seguridad de credenciales

**Compute**
- [ ] Cloud Run deployments
- [ ] Cloud Functions
- [ ] CI/CD con Cloud Build
- [ ] Container management

**Databases**
- [ ] Cloud SQL
- [ ] Firestore
- [ ] BigQuery
- [ ] Data modeling

**Storage**
- [ ] Cloud Storage buckets
- [ ] Lifecycle policies
- [ ] Signed URLs
- [ ] Access control

**Security**
- [ ] IAM roles y permissions
- [ ] Security Command Center
- [ ] Secret Manager
- [ ] Compliance

**Costos**
- [ ] Billing analysis
- [ ] Cost optimization
- [ ] Budget alerts
- [ ] Resource sizing

**AI/ML**
- [ ] Vision API
- [ ] Natural Language API
- [ ] Content moderation
- [ ] ML integrations

---

## ğŸ’¡ Mejores PrÃ¡cticas

### 1. IAM - Least Privilege
```
âœ… Bueno:
- Roles especÃ­ficos por servicio
- Service accounts por aplicaciÃ³n
- Regular audits de permisos
- Remove unused permissions

âŒ Evita:
- Editor/Owner roles generales
- Shared service accounts
- Never audit permissions
- Grant all access "por si acaso"
```

### 2. OptimizaciÃ³n de Costos
```
âœ… Bueno:
- Right-size recursos regularmente
- Lifecycle policies en Storage
- Committed use para workloads predecibles
- Monitor y alerta de costos

âŒ Evita:
- Over-provision recursos
- Ignorar billing reports
- No usar committed use
- Dejar recursos idle
```

### 3. Security
```
âœ… Bueno:
- Security Command Center activo
- Regular security scans
- Secrets en Secret Manager
- Network isolation

âŒ Evita:
- Disable security features
- Hardcode secrets
- Public exposure default
- No monitoring de security
```

### 4. Serverless Best Practices
```
âœ… Bueno:
- Cloud Run para APIs
- Functions para event-driven
- Auto-scaling configurado
- Cold start optimization

âŒ Evita:
- Always-on cuando no necesario
- No configurar limits
- Ignore cold starts
- Synchronous cuando async mejor
```

### 5. Observability
```
âœ… Bueno:
- Cloud Logging habilitado
- Cloud Monitoring dashboards
- Alertas proactivas
- Tracing distribuido

âŒ Evita:
- Deploy sin logs
- No alerts configuradas
- Reactive troubleshooting
- No performance monitoring
```

---

## ğŸš€ Siguiente Nivel

1. **Advanced GCP Services**
   - Anthos (hybrid/multi-cloud)
   - Apigee (API management)
   - Dataflow (stream processing)
   - Pub/Sub (messaging)

2. **Multi-Cloud**
   - GCP + AWS
   - GCP + Azure
   - Cross-cloud architecture
   - Data replication

3. **ML/AI Advanced**
   - Vertex AI custom models
   - AutoML
   - AI Platform Pipelines
   - TensorFlow on GCP

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n
- [GCP Documentation](https://cloud.google.com/docs)
- [Cloud Run Docs](https://cloud.google.com/run/docs)
- [Firestore Docs](https://cloud.google.com/firestore/docs)
- [BigQuery Docs](https://cloud.google.com/bigquery/docs)

### Learning
- [Google Cloud Skills Boost](https://www.cloudskillsboost.google/)
- [GCP Architecture Framework](https://cloud.google.com/architecture/framework)
- [GCP Best Practices](https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations)

### Tools
- [Cloud Console](https://console.cloud.google.com)
- [gcloud CLI](https://cloud.google.com/sdk/gcloud)
- [Cloud Shell](https://cloud.google.com/shell)

---

**Â¡SubcapÃ­tulo 9.F Completo!**

Has aprendido a gestionar Google Cloud Platform con Claude Code. Ahora puedes desplegar aplicaciones serverless, gestionar bases de datos, optimizar costos, asegurar infraestructura y usar servicios de IA/ML.

**Anterior**: `capitulo_09_mcp_vercel.md` (Vercel MCP)
**Siguiente**: `capitulo_09_mcp_alby.md` (Alby MCP)
